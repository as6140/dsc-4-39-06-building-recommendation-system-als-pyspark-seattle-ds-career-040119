{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Recommendation System in PySpark - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this last lab, we will implement a a movie recommendation system using ALS in Spark programming environment. Spark's machine learning libraray `ml` comes packaged with a very efficient imeplementation of ALS algorithm that we looked at in the previous lesson. The lab will require you to put into pratice your spark programming skills for creating and manipulating pyspark DataFrames. We will go through a step-by-step process into developing a movie recommendation system using ALS and pyspark using the MovieLens Dataset that we used in a previous lab.\n",
    "\n",
    "Note: You are advised to refer to [PySpark Documentation](http://spark.apache.org/docs/2.2.0/api/python/index.html) heavily for completing this lab as it will introduce a few new methods. \n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Demonstrate an understanding on how recommendation systems are being used for personalization of online services/products\n",
    "* Parse and filter datasets into Spark RDDs, performing basic feature selection\n",
    "* Run a brief hyper-parameter selection activity through a scalable grid search\n",
    "* Train and evaluate the predictive performance of recommendation system\n",
    "* Generate predictions from the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Recommendation System\n",
    "\n",
    "We have seen how recommender/Recommendation Systems have played an  integral parts in the success of Amazon (Books, Items), Pandora/Spotify (Music), Google (News, Search), YouTube (Videos) etc.  For Amazon these systems bring more than 30% of their total revenues. For Netflix service, 75% of movies that people watch are based on some sort of recommendation.\n",
    "\n",
    "> The goal of Recommendation Systems is to find what is likely to be of interest to the user. This enables organizations to offer a high level of personalization and customer tailored services.\n",
    "\n",
    "\n",
    "For online video content services like Netflix and Hulu, the need to build robust movie recommendation systems is extremely important. An example of recommendation system is such as this:\n",
    "\n",
    "1.    User A watches Game of Thrones and Breaking Bad.\n",
    "2.    User B performs a search query for Game of Thrones.\n",
    "3.    The system suggests Breaking Bad to user B from data collected about user A.\n",
    "\n",
    "\n",
    "This lab will guide you through a step-by-step process into developing such a movie recommendation system. We will use the MovieLens dataset to build a movie recommendation system using the collaborative filtering technique with Spark's Alternating Least Saqures implementation. After building that recommendation system, we will go through the process of adding a new user to the dataset with some new ratings and obtaining new recommendations for that user.\n",
    "\n",
    "### Importing the Data\n",
    "To begin with:\n",
    "* initialize a SparkSession object\n",
    "* import the dataset found at './data/ratings.csv' into a pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate SparkSession object\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    "         .master(\"local[*]\") #local[4]: run on my computer, use 4 processors, \n",
    "                             #local[*]: use a processor for each core\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv  ratings.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ratings.csv: ASCII text, with CRLF line terminators\r\n"
     ]
    }
   ],
   "source": [
    "!file data/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\r",
      "\r\n",
      "1,1,4.0,964982703\r",
      "\r\n",
      "1,3,4.0,964981247\r",
      "\r\n",
      "1,6,4.0,964982224\r",
      "\r\n",
      "1,47,5.0,964983815\r",
      "\r\n",
      "1,50,5.0,964982931\r",
      "\r\n",
      "1,70,3.0,964982400\r",
      "\r\n",
      "1,101,5.0,964980868\r",
      "\r\n",
      "1,110,4.0,964982176\r",
      "\r\n",
      "1,151,5.0,964984041\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head data/ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If userId wasn't numeric, you'd have to encode it numerically (ex. github username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset into pyspark DataFrame\n",
    "movie_ratings = spark.read.csv(\"data/ratings.csv\",header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "#inferSchema reads through doc twice, takes longer\n",
    "#header helps recognize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArrayType',\n",
       " 'AtomicType',\n",
       " 'BinaryType',\n",
       " 'BooleanType',\n",
       " 'ByteType',\n",
       " 'CloudPickleSerializer',\n",
       " 'DataType',\n",
       " 'DataTypeSingleton',\n",
       " 'DateConverter',\n",
       " 'DateType',\n",
       " 'DatetimeConverter',\n",
       " 'DecimalType',\n",
       " 'DoubleType',\n",
       " 'FloatType',\n",
       " 'FractionalType',\n",
       " 'IntegerType',\n",
       " 'IntegralType',\n",
       " 'JavaClass',\n",
       " 'LongType',\n",
       " 'MapType',\n",
       " 'NullType',\n",
       " 'NumericType',\n",
       " 'Row',\n",
       " 'ShortType',\n",
       " 'SparkContext',\n",
       " 'StringType',\n",
       " 'StructField',\n",
       " 'StructType',\n",
       " 'TimestampType',\n",
       " 'UserDefinedType',\n",
       " '_FIXED_DECIMAL',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_acceptable_types',\n",
       " '_all_atomic_types',\n",
       " '_all_complex_types',\n",
       " '_array_signed_int_typecode_ctype_mappings',\n",
       " '_array_type_mappings',\n",
       " '_array_unsigned_int_typecode_ctype_mappings',\n",
       " '_atomic_types',\n",
       " '_check_dataframe_convert_date',\n",
       " '_check_dataframe_localize_timestamps',\n",
       " '_check_series_convert_date',\n",
       " '_check_series_convert_timestamps_internal',\n",
       " '_check_series_convert_timestamps_local_tz',\n",
       " '_check_series_convert_timestamps_localize',\n",
       " '_check_series_convert_timestamps_tz_local',\n",
       " '_check_series_localize_timestamps',\n",
       " '_create_converter',\n",
       " '_create_row',\n",
       " '_create_row_inbound_converter',\n",
       " '_get_local_timezone',\n",
       " '_has_nulltype',\n",
       " '_infer_schema',\n",
       " '_infer_type',\n",
       " '_int_size_to_type',\n",
       " '_make_type_verifier',\n",
       " '_merge_type',\n",
       " '_need_converter',\n",
       " '_parse_datatype_json_string',\n",
       " '_parse_datatype_json_value',\n",
       " '_parse_datatype_string',\n",
       " '_test',\n",
       " '_type_mappings',\n",
       " '_typecode',\n",
       " 'array',\n",
       " 'base64',\n",
       " 'basestring',\n",
       " 'calendar',\n",
       " 'ctypes',\n",
       " 'datetime',\n",
       " 'decimal',\n",
       " 'dt',\n",
       " 'from_arrow_schema',\n",
       " 'from_arrow_type',\n",
       " 'json',\n",
       " 'long',\n",
       " 'platform',\n",
       " 're',\n",
       " 'register_input_converter',\n",
       " 'size',\n",
       " 'sys',\n",
       " 'time',\n",
       " 'to_arrow_schema',\n",
       " 'to_arrow_type',\n",
       " 'unicode']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OR\n",
    "#pass in schema to specify column names & column types for a large dataset\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "                                StructType,\n",
    "                                StructField,\n",
    "                                IntegerType,\n",
    "                                FloatType,\n",
    "                                LongType,)\n",
    "dir(pyspark.sql.types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "[\n",
    "    StructField('userId', IntegerType()),\n",
    "    StructField('movieId', IntegerType()),\n",
    "    StructField('rating', FloatType()),\n",
    "    StructField('timestamp', LongType())\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float, timestamp: bigint]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings = spark.read.csv(\"data/ratings.csv\",\n",
    "                               header=True, \n",
    "                               inferSchema=False,\n",
    "                               schema=schema)\n",
    "\n",
    "movie_ratings.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types of each of the values to ensure that they are a type that makes sense given the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we want to cross-validate, we should do a temporal split on timestamps in recommendation systems, SO do NOT drop the timestamp column\n",
    "- New users will have new NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Alternating Least Squares Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this dataset is already preprocessed for us, we can go ahead and fit the Alternating Least Squares model.\n",
    "\n",
    "* Import the ALS module from pyspark.ml.recommendation.\n",
    "* Use the randomSplit method on the pyspark DataFrame to separate the dataset into a training and test set\n",
    "* Fit the Alternating Least Squares Model to the training dataset. Make sure to set the userCol, itemCol, and ratingCol to the appropriate names given this dataset. Then fit the data to the training set and assign it to a variable model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "#DON'T USE MLLIB BECAUSE IT'S NOT DATAFRAME AWARE\n",
    "\n",
    "#USE ML, even though pyspark documentation may appear as MLLIB even though it's talking about the new ML library\n",
    "#SPARK changes fast, make sure your documentation is using the same version as you\n",
    "\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "#ALS creates an ALS model, ALSModel lets you save a model and load it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFAULTS:\n",
    "#ALS(rank=10, maxIter=10, regParam=0.1, numUserBlocks=10, numItemBlocks=10, implicitPrefs=False, \n",
    "#alpha=1.0, userCol='user', itemCol='item', seed=None, ratingCol='rating', nonnegative=False, \n",
    "#checkpointInterval=10,intermediateStorageLevel='MEMORY_AND_DISK', \n",
    "#finalStorageLevel='MEMORY_AND_DISK', coldStartStrategy='nan')\n",
    "\n",
    "# split into training and testing sets\n",
    "#SPECIFY WHICH COLUMNS ARE USER, ITEM, and RATING\n",
    "als = ALS(\n",
    "        rank=10,\n",
    "        maxIter=10,\n",
    "        userCol='userId',\n",
    "        itemCol='movieId',\n",
    "        ratingCol='rating',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_1ccaf09c4b2d"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "\n",
    "als.fit(movie_ratings)\n",
    "#EVERYTHING'S IMMUTABLE - WE MUST ACTUALLY NAME AN OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = als.fit(movie_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = als_model.transform(movie_ratings)\n",
    "#everything just uses fit & transform instead of sklearn's fit, transform, predict, predict_proba mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: float, timestamp: bigint, prediction: float]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+----------+\n",
      "|userId|movieId|rating|timestamp|prediction|\n",
      "+------+-------+------+---------+----------+\n",
      "|   191|    148|   5.0|829760897|  4.923959|\n",
      "|   133|    471|   4.0|843491793| 3.2797976|\n",
      "|   597|    471|   2.0|941558175| 3.8111665|\n",
      "|   385|    471|   4.0|850766697| 3.3658185|\n",
      "|   436|    471|   3.0|833530187|  3.523111|\n",
      "+------+-------+------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5) #first run after .persist() isn't fast, 2nd run after both .persist() and .show() IS FASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+---------+\n",
      "|userId|movieId|rating|timestamp|     pred|\n",
      "+------+-------+------+---------+---------+\n",
      "|   191|    148|   5.0|829760897| 4.923959|\n",
      "|   133|    471|   4.0|843491793|3.2797976|\n",
      "|   597|    471|   2.0|941558175|3.8111665|\n",
      "|   385|    471|   4.0|850766697|3.3658185|\n",
      "|   436|    471|   3.0|833530187| 3.523111|\n",
      "+------+-------+------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make new dataframe with column renamed, show first 5 lines, throws it away\n",
    "predictions.withColumnRenamed('prediction', 'pred').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[0.2496262937784195, -0.7958771586418152, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>[-0.6927688717842102, 0.20887841284275055, 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           features\n",
       "0  10  [0.2496262937784195, -0.7958771586418152, 0.25...\n",
       "1  20  [-0.6927688717842102, 0.20887841284275055, 0.4..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.userFactors.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[-0.8358665108680725, -0.028308473527431488, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>[0.23314112424850464, 0.123916856944561, 0.611...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           features\n",
       "0  10  [-0.8358665108680725, -0.028308473527431488, 0...\n",
       "1  20  [0.23314112424850464, 0.123916856944561, 0.611..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model.itemFactors.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId,title,genres\r",
      "\r\n",
      "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\r",
      "\r\n",
      "2,Jumanji (1995),Adventure|Children|Fantasy\r",
      "\r\n",
      "3,Grumpier Old Men (1995),Comedy|Romance\r",
      "\r\n",
      "4,Waiting to Exhale (1995),Comedy|Drama|Romance\r",
      "\r\n",
      "5,Father of the Bride Part II (1995),Comedy\r",
      "\r\n",
      "6,Heat (1995),Action|Crime|Thriller\r",
      "\r\n",
      "7,Sabrina (1995),Comedy|Romance\r",
      "\r\n",
      "8,Tom and Huck (1995),Adventure|Children\r",
      "\r\n",
      "9,Sudden Death (1995),Action\r",
      "\r\n",
      "10,GoldenEye (1995),Action|Adventure|Thriller\r",
      "\r\n",
      "11,\"American President, The (1995)\",Comedy|Drama|Romance\r",
      "\r\n",
      "12,Dracula: Dead and Loving It (1995),Comedy|Horror\r",
      "\r\n",
      "13,Balto (1995),Adventure|Animation|Children\r",
      "\r\n",
      "14,Nixon (1995),Drama\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 data/movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT's HAPPENING BEHIND THE SCENES, DOT-PRODUCT\n",
    "user_factors = als_model.userFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors = als_model.itemFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2496262937784195,\n",
       " -0.7958771586418152,\n",
       " 0.25280100107192993,\n",
       " -0.33441755175590515,\n",
       " 1.3946477174758911,\n",
       " -1.0567063093185425,\n",
       " 0.24984325468540192,\n",
       " 0.300751268863678,\n",
       " 0.19300296902656555,\n",
       " -0.7851032018661499]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call features data itself from a Row object\n",
    "user_factors[user_factors['id'] == 10].first()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "billy_row = user_factors[user_factors['id'] == 10].first() \n",
    "#.first() takes the Row object out of the 1-row Spark DataFrame\n",
    "billy_factors = np.array(billy_row['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulp_row = item_factors[item_factors['id'] == 296].first()\n",
    "pulp_factors = np.array(pulp_row['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24962629, -0.79587716,  0.252801  , -0.33441755,  1.39464772,\n",
       "       -1.05670631,  0.24984325,  0.30075127,  0.19300297, -0.7851032 ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billy_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.55188572,  0.84363765,  0.21665037,  0.17438513,  0.63840616,\n",
       "       -1.6038481 ,  0.08963302,  0.27322373,  1.381253  , -0.1680087 ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulp_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2754596446813307"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billy_factors @ pulp_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "billy_preds = predictions[predictions['userId'] == 10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|    10|    296|   1.0|1455303387| 2.2754595|\n",
      "|    10|    356|   3.5|1455301685| 3.5585384|\n",
      "|    10|    588|   4.0|1455306173| 3.3146539|\n",
      "|    10|    597|   3.5|1455357645| 3.3858886|\n",
      "|    10|    912|   4.0|1455302254| 3.2757502|\n",
      "|    10|   1028|   0.5|1455306152| 2.6577158|\n",
      "|    10|   1088|   3.0|1455619275| 3.4713135|\n",
      "|    10|   1247|   3.0|1455303518|  2.597934|\n",
      "|    10|   1307|   3.0|1455357613| 3.0849853|\n",
      "|    10|   1784|   3.5|1455301699| 3.0649784|\n",
      "|    10|   1907|   4.0|1455306183| 3.3260531|\n",
      "|    10|   2571|   0.5|1455356378| 3.3142972|\n",
      "|    10|   2671|   3.5|1455357517| 3.5754137|\n",
      "|    10|   2762|   0.5|1455356388|  2.750549|\n",
      "|    10|   2858|   1.0|1455356578|  2.703698|\n",
      "|    10|   2959|   0.5|1455356582| 2.5517616|\n",
      "|    10|   3578|   4.0|1455356591| 3.3524153|\n",
      "|    10|   3882|   3.0|1455398344| 3.1930141|\n",
      "|    10|   4246|   3.5|1455302676|  3.374065|\n",
      "|    10|   4306|   4.5|1455356595| 3.8530211|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "billy_preds.sort('movieId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#als_model.recommendForAllUsers\n",
    "recs = als_model.recommendForAllUsers(numItems=10) #recommeend 10 things for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[3925, 4.834355]...|\n",
      "|   463|[[5075, 5.186709]...|\n",
      "|   496|[[8477, 5.4480753...|\n",
      "|   148|[[183897, 4.57298...|\n",
      "|   540|[[3379, 5.275497]...|\n",
      "|   392|[[84847, 5.224326...|\n",
      "|   243|[[72171, 6.19093]...|\n",
      "|    31|[[5466, 5.4735403...|\n",
      "|   516|[[8477, 4.9331756...|\n",
      "|   580|[[5075, 5.3298316...|\n",
      "|   251|[[3379, 5.7613378...|\n",
      "|   451|[[3379, 5.454221]...|\n",
      "|    85|[[25850, 5.529511...|\n",
      "|   137|[[3379, 4.742041]...|\n",
      "|    65|[[3379, 4.792878]...|\n",
      "|   458|[[32892, 5.483429...|\n",
      "|   481|[[299, 4.364671],...|\n",
      "|    53|[[33649, 6.954679...|\n",
      "|   255|[[74754, 5.386463...|\n",
      "|   588|[[3379, 4.5398135...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recs.persist().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=32892, rating=4.977327823638916),\n",
       " Row(movieId=86320, rating=4.826628684997559),\n",
       " Row(movieId=3682, rating=4.6353936195373535),\n",
       " Row(movieId=110130, rating=4.558963298797607),\n",
       " Row(movieId=71579, rating=4.544266700744629),\n",
       " Row(movieId=7169, rating=4.480790138244629),\n",
       " Row(movieId=67618, rating=4.456949710845947),\n",
       " Row(movieId=7121, rating=4.4546356201171875),\n",
       " Row(movieId=8869, rating=4.428635597229004),\n",
       " Row(movieId=113275, rating=4.419461727142334)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs[recs['userId']==10].first()['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32892,Ivan's Childhood (a.k.a. My Name is Ivan) (Ivanovo detstvo) (1962),Drama|War\n",
      "86320,Melancholia (2011),Drama|Sci-Fi\n"
     ]
    }
   ],
   "source": [
    "!grep 32892 < data/movies.csv\n",
    "!grep 86320 < data/movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE error WITH RMSE\n",
    "\n",
    "#IN REAL LIFE, AN ERROR ON THE HIGH END (WHAT YOU RECOMMEND) IS WAY WORSE THAN AN ERROR ON THE LOW END\n",
    "\n",
    "#USERS REVEALED PREFERENCE > STATED PREFERENCE\n",
    "\n",
    "#YOU CAN PULL OUT USER AND ITEM FACTORS INTO NUMPY ARRAYS, MATH IS EASY ONCE FACORIZATION IS DONE\n",
    "\n",
    "#ALS RANDOMLY INITIALIZES ENTRIES IN USER VECTORS FOR COLD START\n",
    "#ALTERNATIVE: impute initial entries in a way that makes common sense for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "billy_pulp_preds =  billy_preds[billy_preds['movieId'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+----------+\n",
      "|userId|movieId|rating|timestamp|prediction|\n",
      "+------+-------+------+---------+----------+\n",
      "+------+-------+------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've fit the model, and it's time to evaluate it to determine just how well it performed.\n",
    "\n",
    "* import `RegressionEvalutor` from pyspark.ml.evaluation\n",
    "* generate predictions with your model for the test set by using the `transform` method on your ALS model\n",
    "* evaluate your model and print out the RMSE from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9968853671625669\n"
     ]
    }
   ],
   "source": [
    "# importing appropriate library\n",
    "\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to Find the Optimal Model\n",
    "\n",
    "Let's now find the optimal values for the parameters of the ALS model. Use the built-in Cross Validator in pyspark with a suitable param grid and determine the optimal model. Try with the parameters:\n",
    "\n",
    "* regularization = [0.01,0.001,0.1])\n",
    "* rank = [4,10,50]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# initialize the ALS model\n",
    "\n",
    "\n",
    "# create the parameter grid              \n",
    "\n",
    "\n",
    "## instantiating crossvalidator estimator\n",
    "\n",
    "\n",
    "# We see the best model has a rank of 50, so we will use that in our future models with this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating the names of the movies\n",
    "\n",
    "When we make recommendations, it would be ideal if we could have the actual name of the movie be used rather than just an ID. There is another file called './data/movies.csv' that contains all of the names of the movies matched up to the movie_id that we have in the ratings dataset.\n",
    "\n",
    "* import the data into a Spark DataFrame\n",
    "* look at the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=1, title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(movieId=2, title='Jumanji (1995)', genres='Adventure|Children|Fantasy'),\n",
       " Row(movieId=3, title='Grumpier Old Men (1995)', genres='Comedy|Romance'),\n",
       " Row(movieId=4, title='Waiting to Exhale (1995)', genres='Comedy|Drama|Romance'),\n",
       " Row(movieId=5, title='Father of the Bride Part II (1995)', genres='Comedy')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = None\n",
    "\n",
    "movie_titles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will eventually be matching up the movie_ids with the movie titles. In the cell below, create a function `name_retriever` that takes in a movie_id and returns a string that. \n",
    "\n",
    "> Hint: It's possible to do this operation in one line with the `df.where` or the `df.filter` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_retriever(movie_id,movie_title_df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winnie the Pooh and the Blustery Day (1968)\n"
     ]
    }
   ],
   "source": [
    "print(name_retriever(1023,movie_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Recommendations\n",
    "\n",
    "Now it's time to actually get some recommendations! The ALS model has built in methods called `recommendForUserSubset` and `recommendForAllUsers`. We'll start off with using a subset of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = movie_ratings.select(als.getUserCol()).distinct().limit(1)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "recs = userSubsetRecs.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see we have a list of rows with recommended items. Now try and get the name of the top recommended movie by way of the function you just created, using number one item for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pirate Radio (2009)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use indexing to obtain the movie id of top predicted rated item\n",
    "first_recommendation = recs[0]['recommendations'][0][0]\n",
    "\n",
    "# use the name retriever function to get the values\n",
    "name_retriever(first_recommendation,movie_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also make recommendations for everyone, although this will take longer. In the next line, we are creating an RDD with the top 5 recommendations for every user and then selecting one user to find out his predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendForAllUsers(5)\n",
    "recommendations.where(recommendations.userId == 3).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Predictions for a New User\n",
    "\n",
    "Now, it's time to put together all that you've learned in this section to create a function that will take in a new user and some movies they've rated and then return n number of highest recommended movies. This function will have multiple different steps to it:\n",
    "\n",
    "* adding the new ratings into the dataframe (hint: look into using the union df method)\n",
    "* fitting the als model to\n",
    "* make recommendations for the user of choice\n",
    "* print out the names of the top n recommendations in a reader-friendly manner\n",
    "\n",
    "The function should take in the parameters:\n",
    "* user_id : int \n",
    "* new_ratings : list of tuples in the format (user_id,item_id,rating)\n",
    "* rating_df : spark DF containing ratings\n",
    "* movie_title_df : spark DF containing movie titles\n",
    "* num_recs : int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rate these new movies\n",
    "\n",
    "```python\n",
    "[Row(movieId=3253, title=\"Wayne's World (1992)\", genres='Comedy'),\n",
    " Row(movieId=2459, title='Texas Chainsaw Massacre, The (1974)', genres='Horror'),\n",
    " Row(movieId=2513, title='Pet Sematary (1989)', genres='Horror'),\n",
    " Row(movieId=6502, title='28 Days Later (2002)', genres='Action|Horror|Sci-Fi'),\n",
    " Row(movieId=1091, title=\"Weekend at Bernie's (1989)\", genres='Comedy'),\n",
    "Row(movieId=441, title='Dazed and Confused (1993)', genres='Comedy'),\n",
    "Row(movieId=370, title='Naked Gun 33 1/3: The Final Insult (1994)', genres='Action|Comedy')]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user_recs(user_id,new_ratings,rating_df,movie_title_df,num_recs):\n",
    "    # turn the new_recommendations list into a spark DataFrame\n",
    "    \n",
    "    \n",
    "    # combine the new ratings df with the rating_df\n",
    "  \n",
    "    \n",
    "    # create an ALS model and fit it\n",
    "\n",
    "    \n",
    "    # make recommendations for all users using the recommendForAllUsers method\n",
    "\n",
    "    \n",
    "    # get recommendations specifically for the new user that has been added to the DataFrame\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation 1: Star Wars: Episode IV - A New Hope (1977)  | predicted score :5.517341136932373\n",
      "Recommendation 2: Usual Suspects, The (1995)  | predicted score :5.442122936248779\n",
      "Recommendation 3: In the Name of the Father (1993)  | predicted score :5.3851237297058105\n",
      "Recommendation 4: Star Wars: Episode V - The Empire Strikes Back (1980)  | predicted score :5.381286144256592\n",
      "Recommendation 5: Fight Club (1999)  | predicted score :5.361552715301514\n",
      "Recommendation 6: Monty Python and the Holy Grail (1975)  | predicted score :5.347217559814453\n",
      "Recommendation 7: Willy Wonka & the Chocolate Factory (1971)  | predicted score :5.328979969024658\n",
      "Recommendation 8: Who Framed Roger Rabbit? (1988)  | predicted score :5.324649810791016\n",
      "Recommendation 9: Clerks (1994)  | predicted score :5.305201530456543\n",
      "Recommendation 10: Office Space (1999)  | predicted score :5.297811985015869\n"
     ]
    }
   ],
   "source": [
    "# try out your function with the movies listed above\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have it! Our recommendation system is generating recommendations for the top 10 movies. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Level up - Optional \n",
    "\n",
    "\n",
    "* Create a user interface to allow users to easily choose items and get recommendations.\n",
    "\n",
    "* Use IMDB links to scrape user reviews from IMDB and using basic NLP techniques, create extra embeddings for ALS model. \n",
    "\n",
    "* Create a hybrid recommender system using features like genre\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we learned how to build a model using Spark, how to perform some parameter selection, and how to update the model every time that new user preferences come in. We looked at how Spark's ALS implementation can be be used to build a scalable and efficient recommendation system. We also saw that such systems can become computationally expensive and using them with an online system could be a problem with traditional computational platforms. Spark's distributed computing architecture provides a great solution to deploy such recommendation systems for real world applications (think Amazon, Spotify)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
